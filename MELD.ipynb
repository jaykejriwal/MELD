{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First step \n",
    "## Download the MELD corpus to a specific location\n",
    "## This program converts each video files (.mp4) into audio (.wav) file format \n",
    "\n",
    "#Read All files and convert video files to wav file format\n",
    "import os\n",
    "\n",
    "#Specify path of input folder\n",
    "audio_path = '/home/jay_kejriwal/MELD/MELD.Raw/dev_splits_complete'\n",
    "#Specify path of output folder\n",
    "output_path = '/home/jay_kejriwal/MELD/MELD.Raw/dev_splits_resampled'\n",
    "#Do this for all files i.e. train,val sets  \n",
    "\n",
    "all_files = os.listdir(audio_path)\n",
    "for root, dirs, files in os.walk(audio_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4'):\n",
    "            out_name= os.path.basename(file[:-4])+'.wav'\n",
    "            output=os.path.join(output_path, out_name)\n",
    "            cmd_str = f\"ffmpeg -i {os.path.join(root, file)} -ac 1 -ar 16000 -f wav -vn {output}\"\n",
    "            print(cmd_str)\n",
    "            os.system(cmd_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Second step\n",
    "## This program reads all csv files and merge them into one big csv file\n",
    "## The csv file has information about Utterance, Season, Episode, Speaker information \n",
    "\n",
    "#Pre-process text files\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "# Specify path of dataset folder\n",
    "csv_files = glob.glob(r'D:\\D drive\\MELD corpus\\MELD_Dyadic\\*.csv',recursive=True)\n",
    "\n",
    "# Specify output path\n",
    "out_name=r'D:\\D drive\\MELD corpus\\output\\MELD_Dyadic_all.csv'\n",
    "df_csv_append = pd.DataFrame()\n",
    " \n",
    "# append the CSV files\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['mainfile'] = os.path.basename(file)[:-4]\n",
    "    df_csv_append = df_csv_append.append(df, ignore_index=True)\n",
    " \n",
    "\n",
    "df_csv_append.sort_values(['Season', 'Episode'], ascending=[True, True], inplace=True)\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df_csv_append['mainfile'] == 'train_sent_emo_dya'),\n",
    "    (df_csv_append['mainfile'] == 'dev_sent_emo_dya'),\n",
    "    (df_csv_append['mainfile'] == 'test_sent_emo_dya')\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [r'D:\\D drive\\MELD corpus\\train_splits_resampled', r'D:\\D drive\\MELD corpus\\dev_splits_complete_resampled', r'D:\\D drive\\MELD corpus\\output_repeated_splits_test_resampled']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_csv_append['File_path'] = np.select(conditions, values)\n",
    "df_csv_append[['Old_Dialogue_ID', 'Old_Utterance_ID','Season','Episode']] = df_csv_append[['Old_Dialogue_ID', 'Old_Utterance_ID','Season','Episode']].astype(str)\n",
    "df_csv_append[\"Full_path\"] = df_csv_append['File_path']+'\\dia' + (df_csv_append['Old_Dialogue_ID'])+'_utt'+ (df_csv_append['Old_Utterance_ID']) + '.wav'\n",
    "df_csv_append.to_csv(out_name, index=False,header=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Third step\n",
    "## This program concatenates ajacent emotional state of dyads. \n",
    "## For instance, if speaker A's turn is labelled as positive emotional state and speaker B is under \n",
    "## negative emotional state then program concatenates the two emotional state and writes it as positive-negative emotional state\n",
    "\n",
    "#Program to concatenate adjacent emotional states\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from functools import reduce\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import subprocess\n",
    "import re\n",
    "import glob\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import wave\n",
    "import json\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Specify input \n",
    "file_name=r\"D:\\D drive\\MELD corpus\\output\\MELD_Dyadic_all.csv\"\n",
    "#Specify output \n",
    "output_filename=r'D:\\D drive\\MELD corpus\\output\\MELD_Dyadic_all_pairdistance.csv'\n",
    "emotion=[]\n",
    "sentiment=[]\n",
    "old_dialogueid=[]\n",
    "old_utteranceid=[]\n",
    "speaker=[]\n",
    "adjacent_distance=[]\n",
    "df = pd.read_csv(file_name,delimiter='\\t')\n",
    "df=df.applymap(str)\n",
    "for i in range(len(df)-1):\n",
    "    if(df.loc[i, \"Old_Dialogue_ID\"]==df.loc[i+1, \"Old_Dialogue_ID\"] and df.loc[i, \"Speaker\"]!=df.loc[i+1, \"Speaker\"]):\n",
    "        \n",
    "        emotion_x=df.loc[i, \"Emotion\"]\n",
    "        emotion_y=df.loc[i+1, \"Emotion\"]\n",
    "        emotion_z=emotion_x+'-'+emotion_y\n",
    "        emotion.append(emotion_z)\n",
    "        \n",
    "        sentiment_x=df.loc[i, \"Sentiment\"]\n",
    "        sentiment_y=df.loc[i+1, \"Sentiment\"]\n",
    "        sentiment_z=sentiment_x+'-'+sentiment_y\n",
    "        sentiment.append(sentiment_z)\n",
    "        \n",
    "        old_dialogueid_x=df.loc[i, \"Old_Dialogue_ID\"]\n",
    "        old_dialogueid_y=df.loc[i+1, \"Old_Dialogue_ID\"]\n",
    "        old_dialogueid_z=old_dialogueid_x+'-'+old_dialogueid_y\n",
    "        old_dialogueid.append(old_dialogueid_z)        \n",
    "        \n",
    "        old_utteranceid_x=df.loc[i, \"Old_Utterance_ID\"]\n",
    "        old_utteranceid_y=df.loc[i+1, \"Old_Utterance_ID\"]\n",
    "        old_utteranceid_z=old_utteranceid_x+'-'+old_utteranceid_y\n",
    "        old_utteranceid.append(old_utteranceid_z)\n",
    "\n",
    "        speaker_x=df.loc[i, \"Speaker\"]\n",
    "        speaker_y=df.loc[i+1, \"Speaker\"]\n",
    "        speaker_z=speaker_x+'-'+speaker_y\n",
    "        speaker.append(speaker_z)\n",
    "\n",
    "df1 = pd.DataFrame(data=None)\n",
    "df1['Old_Dialogue_ID'] = pd.Series(old_dialogueid)\n",
    "df1['Old_Utterance_ID'] = pd.Series(old_utteranceid)\n",
    "df1['Speaker'] = pd.Series(speaker)\n",
    "df1['Emotion'] = pd.Series(emotion)\n",
    "df1['Sentiment'] = pd.Series(sentiment)\n",
    "df1.to_csv(output_filename, index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fourth step\n",
    "## This program extracts acoustic-prosodic features from each turn. \n",
    "## The program extracts features from file generated in Step 2  \n",
    "## The program uses Praat script and extracts pitch, intensity, and voice quality features\n",
    "\n",
    "#Program to extract acoustic-prosodic feature\n",
    "import pandas as pd\n",
    "import csv\n",
    "import subprocess\n",
    "import re\n",
    "import glob\n",
    "import os,sys\n",
    "import numpy as np\n",
    "\n",
    "#Specify input\n",
    "file_name=r\"D:\\D drive\\MELD corpus\\output\\MELD_Dyadic_all.csv\"\n",
    "#Specify output\n",
    "output_filename=r\"D:\\D drive\\MELD corpus\\output\\MELD_Dyadic_all_ap_new_MELD_dyadic.txt\"\n",
    "#Specify Praat path\n",
    "praat = 'D:\\\\D drive\\\\Praat.exe'\n",
    "#Specify Praat script path\n",
    "script= r\"D:\\D drive\\MELD corpus\\Program\\Python_script\\pitch,jitter,shimmer,intensity_emotion.praat\"\n",
    "df = pd.read_csv(file_name,delimiter='\\t')\n",
    "df=df.applymap(str)\n",
    "for i in range(len(df)):\n",
    "    subprocess.call([praat, '--run', script, df.loc[i, \"Full_path\"], output_filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fifth step\n",
    "\n",
    "## Merge files generated in Step 3 (MELD_Dyadic_all.csv) and 4 (MELD_Dyadic_all_ap_new_MELD_dyadic) manually using Microsoft Excel \n",
    "## The merged file can be named as Merged_dyadic_ap.csv\n",
    "\n",
    "## After merging the files execute this code\n",
    "## This program measures speech rate and perform z-score normalizaton \n",
    "\n",
    "#This function meausres speech rate\n",
    "def syllable_count_english(word):\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "\n",
    "    for word in word.lower().split(\" \"):\n",
    "        for i in range(len(word)):\n",
    "            if word[i] in vowels and (i == 0 or word[i-1] not in vowels):\n",
    "                count +=1\n",
    "    return count\n",
    "\n",
    "#Specify input file name\n",
    "ap_filename=r'D:\\D drive\\MELD corpus\\output\\Merged_dyadic_ap.csv'\n",
    "#Specify output file name\n",
    "op_filename=r'D:\\D drive\\MELD corpus\\output\\final_merge1.csv'\n",
    "with open(ap_filename) as csv_file:\n",
    "    df = pd.read_csv(csv_file)\n",
    "df.Utterance=df.Utterance.astype(str)\n",
    "df.Speaker=df.Speaker.astype(str)\n",
    "df['speechrate'] = df['Utterance'].map(syllable_count_english)/(df['duration'])\n",
    "scaled_data = df.copy()\n",
    "for col in ['mean_pitch','min_pitch', 'max_pitch','mean_intensity',\n",
    "            'min_intensity','max_intensity','jitter_local',\n",
    "            'shimmer_local','mean_nhr','speechrate']:\n",
    "    scaled_data[col] = (scaled_data[col] - scaled_data[col].mean()) / scaled_data[col].std()\n",
    "scaled_data.to_csv(op_filename, index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sixth step\n",
    "## Measure adjacent score on each prosodic feature\n",
    "## Program meausres absolute distance on adjacent turns and concatenates emotional state of dyads\n",
    "\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "#Specify input file\n",
    "file_name=r'D:\\D drive\\MELD corpus\\output\\final_merge1.csv'\n",
    "\n",
    "#Specify output file\n",
    "output_filename=r'D:\\D drive\\MELD corpus\\output\\final_ap_pairdistance_abs_prop.csv'\n",
    "speaker=[]\n",
    "adjacent_file_name=[]\n",
    "adjacent_distance_mean_pitch=[]\n",
    "adjacent_distance_min_pitch=[]\n",
    "adjacent_distance_max_pitch=[]\n",
    "adjacent_distance_mean_intensity=[]\n",
    "adjacent_distance_min_intensity=[]\n",
    "adjacent_distance_max_intensity=[]\n",
    "adjacent_distance_jitter=[]\n",
    "adjacent_distance_shimmer=[]\n",
    "adjacent_distance_nhr=[]\n",
    "adjacent_distance_speechrate=[]\n",
    "emotion=[]\n",
    "sentiment=[]\n",
    "old_dialogueid=[]\n",
    "old_utteranceid=[]\n",
    "speaker=[]\n",
    "adjacent_distance=[]\n",
    "\n",
    "df = pd.read_csv(file_name,delimiter=',')\n",
    "\n",
    "df=df.applymap(str)\n",
    "for i in range(len(df)-1):\n",
    "    if(df.loc[i, \"Old_Dialogue_ID\"]==df.loc[i+1, \"Old_Dialogue_ID\"] and df.loc[i, \"Speaker\"]!=df.loc[i+1, \"Speaker\"]):\n",
    "        \n",
    "        emotion_x=df.loc[i, \"Emotion\"]\n",
    "        emotion_y=df.loc[i+1, \"Emotion\"]\n",
    "        emotion_z=emotion_x+'-'+emotion_y\n",
    "        emotion.append(emotion_z)\n",
    "        \n",
    "        sentiment_x=df.loc[i, \"Sentiment\"]\n",
    "        sentiment_y=df.loc[i+1, \"Sentiment\"]\n",
    "        sentiment_z=sentiment_x+'-'+sentiment_y\n",
    "        sentiment.append(sentiment_z)\n",
    "        \n",
    "        old_dialogueid_x=df.loc[i, \"Old_Dialogue_ID\"]\n",
    "        old_dialogueid_y=df.loc[i+1, \"Old_Dialogue_ID\"]\n",
    "        old_dialogueid_z=old_dialogueid_x+'-'+old_dialogueid_y\n",
    "        old_dialogueid.append(old_dialogueid_z)        \n",
    "        \n",
    "        old_utteranceid_x=df.loc[i, \"Old_Utterance_ID\"]\n",
    "        old_utteranceid_y=df.loc[i+1, \"Old_Utterance_ID\"]\n",
    "        old_utteranceid_z=old_utteranceid_x+'-'+old_utteranceid_y\n",
    "        old_utteranceid.append(old_utteranceid_z)\n",
    "\n",
    "        speaker_x=df.loc[i, \"Speaker\"]\n",
    "        speaker_y=df.loc[i+1, \"Speaker\"]\n",
    "        speaker_z=speaker_x+'-'+speaker_y\n",
    "        speaker.append(speaker_z)\n",
    "        \n",
    "        df['mean_pitch']=df['mean_pitch'].astype(np.float)\n",
    "        df['min_pitch']=df['min_pitch'].astype(np.float)\n",
    "        df['max_pitch']=df['max_pitch'].astype(np.float)\n",
    "        df['mean_intensity']=df['mean_intensity'].astype(np.float)\n",
    "        df['min_intensity']=df['min_intensity'].astype(np.float)\n",
    "        df['max_intensity']=df['max_intensity'].astype(np.float)\n",
    "        df['jitter_local']=df['jitter_local'].astype(np.float)\n",
    "        df['shimmer_local']=df['shimmer_local'].astype(np.float)\n",
    "        df['mean_nhr']=df['mean_nhr'].astype(np.float)\n",
    "        df['speechrate']=df['speechrate'].astype(np.float)\n",
    "\n",
    "        pitch_mean_diff=(df.loc[i, \"mean_pitch\"]-df.loc[i+1, \"mean_pitch\"]).__abs__()\n",
    "        adjacent_distance_mean_pitch.append(pitch_mean_diff)\n",
    "        pitch_min_diff=(df.loc[i, \"min_pitch\"]-df.loc[i+1, \"min_pitch\"]).__abs__()\n",
    "        adjacent_distance_min_pitch.append(pitch_min_diff)\n",
    "        pitch_max_diff=(df.loc[i, \"max_pitch\"]-df.loc[i+1, \"max_pitch\"]).__abs__()\n",
    "        adjacent_distance_max_pitch.append(pitch_max_diff)\n",
    "        intensity_mean_diff=(df.loc[i, \"mean_intensity\"]-df.loc[i+1, \"mean_intensity\"]).__abs__()\n",
    "        adjacent_distance_mean_intensity.append(intensity_mean_diff)\n",
    "        intensity_min_diff=(df.loc[i, \"min_intensity\"]-df.loc[i+1, \"min_intensity\"]).__abs__()\n",
    "        adjacent_distance_min_intensity.append(intensity_min_diff)\n",
    "        intensity_max_diff=(df.loc[i, \"max_intensity\"]-df.loc[i+1, \"max_intensity\"]).__abs__()\n",
    "        adjacent_distance_max_intensity.append(intensity_max_diff)\n",
    "        jitter_diff=(df.loc[i, \"jitter_local\"]-df.loc[i+1, \"jitter_local\"]).__abs__()\n",
    "        adjacent_distance_jitter.append(jitter_diff)\n",
    "        shimmer_diff=(df.loc[i, \"shimmer_local\"]-df.loc[i+1, \"shimmer_local\"]).__abs__()\n",
    "        adjacent_distance_shimmer.append(shimmer_diff)\n",
    "        nhr_diff=(df.loc[i, \"mean_nhr\"]-df.loc[i+1, \"mean_nhr\"]).__abs__()\n",
    "        adjacent_distance_nhr.append(nhr_diff)\n",
    "        speechrate_diff=(df.loc[i, \"speechrate\"]-df.loc[i+1, \"speechrate\"]).__abs__()\n",
    "        adjacent_distance_speechrate.append(speechrate_diff)\n",
    "        \n",
    "        \n",
    "df1 = pd.DataFrame(data=None)\n",
    "df1['Old_Dialogue_ID'] = pd.Series(old_dialogueid)\n",
    "df1['Old_Utterance_ID'] = pd.Series(old_utteranceid)\n",
    "df1['Speaker'] = pd.Series(speaker)\n",
    "df1['Emotion'] = pd.Series(emotion)\n",
    "df1['Sentiment'] = pd.Series(sentiment)\n",
    "df1['Mean Pitch distance'] = pd.Series(adjacent_distance_mean_pitch)\n",
    "df1['Min Pitch distance'] = pd.Series(adjacent_distance_min_pitch)\n",
    "df1['Max Pitch distance'] = pd.Series(adjacent_distance_max_pitch)\n",
    "df1['Mean Intensity distance'] = pd.Series(adjacent_distance_mean_intensity)\n",
    "df1['Min Intensity distance'] = pd.Series(adjacent_distance_min_intensity)\n",
    "df1['Max Intensity distance'] = pd.Series(adjacent_distance_max_intensity)\n",
    "df1['Jitter distance'] = pd.Series(adjacent_distance_jitter)\n",
    "df1['Shimmer distance'] = pd.Series(adjacent_distance_shimmer)\n",
    "df1['Mean Nhr distance'] = pd.Series(adjacent_distance_nhr)\n",
    "df1['Speechrate distance'] = pd.Series(adjacent_distance_speechrate)\n",
    "\n",
    "df1.to_csv(output_filename, index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lastly, analysis can be done using R or JASP\n",
    "## R file is provided in the repository "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
